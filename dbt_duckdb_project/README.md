# dbt_duckdb_project

This is a simple `dbt` project using the [DuckDB](https://duckdb.org/) adapter. Itâ€™s part of a local data engineering pipeline that integrates with Apache Airflow.

## ğŸ—‚ Project Structure

```
dbt_duckdb_project/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ full_names.sql
â”‚   â””â”€â”€ schema.yml
â”œâ”€â”€ seeds/
â”‚   â””â”€â”€ people.csv
â”œâ”€â”€ dbt_project.yml
â”œâ”€â”€ profiles.yml
â””â”€â”€ README.md
```

## ğŸš€ How to Run

1. Navigate to the dbt project root:

```bash
cd dbt_duckdb_project
```

2. Run the dbt seed step:

```bash
dbt seed --profiles-dir .
```

3. Run the dbt models:

```bash
dbt run --profiles-dir .
```

4. (Optional) Run tests:

```bash
dbt test --profiles-dir .
```

## âœ… What This Does

- Seeds `people.csv` into DuckDB.
- Transforms it into a model `full_names.sql` with a new `full_name` column.
- Validates data quality with dbt tests (e.g. `not_null`, `unique`).

## ğŸ§  What You Learn

- How to use dbt with DuckDB.
- Seeding and modeling data locally.
- Running and testing dbt models via CLI or Airflow.

---

Built with â¤ï¸ by Melissa Nicholas
